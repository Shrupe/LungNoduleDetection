{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39ef5153-4c01-4b28-8010-6c87107ad8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils import world_to_voxel, extract_patch\n",
    "\n",
    "def normalize_path(path):\n",
    "    return path.replace(\"\\\\\", \"/\")\n",
    "\n",
    "def extract_negative_patches_from_candidates(\n",
    "    candidates_csv,\n",
    "    annotations_csv,\n",
    "    metadata_csv,\n",
    "    output_folder,\n",
    "    patch_size=32,\n",
    "    max_negatives_per_scan=5,\n",
    "    intensity_threshold=0.05  # Mean intensity filter\n",
    "):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    candidates_df = pd.read_csv(candidates_csv)\n",
    "    annotations_df = pd.read_csv(annotations_csv)\n",
    "    metadata_df = pd.read_csv(metadata_csv)\n",
    "\n",
    "    # Convert annotation list for fast lookup\n",
    "    def is_nodule(candidate, annotations_for_scan, distance_threshold=6):\n",
    "        for _, row in annotations_for_scan.iterrows():\n",
    "            distance = np.linalg.norm(np.array(candidate) - np.array([row[\"coordX\"], row[\"coordY\"], row[\"coordZ\"]]))\n",
    "            if distance < distance_threshold:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    for _, meta in tqdm(metadata_df.iterrows(), total=len(metadata_df), desc=\"Extracting Negatives\"):\n",
    "        seriesuid = meta[\"seriesuid\"]\n",
    "        scan_path = meta[\"npz_path\"]\n",
    "        origin = np.array([meta[\"origin_x\"], meta[\"origin_y\"], meta[\"origin_z\"]])\n",
    "        spacing = np.array([meta[\"spacing_x\"], meta[\"spacing_y\"], meta[\"spacing_z\"]])\n",
    "\n",
    "        volume = np.load(scan_path)[\"arr_0\"]\n",
    "        scan_candidates = candidates_df[candidates_df[\"seriesuid\"] == seriesuid]\n",
    "        scan_annotations = annotations_df[annotations_df[\"seriesuid\"] == seriesuid]\n",
    "\n",
    "        # Remove candidates near actual nodules\n",
    "        negative_candidates = []\n",
    "        for _, cand in scan_candidates.iterrows():\n",
    "            if not is_nodule([cand[\"coordX\"], cand[\"coordY\"], cand[\"coordZ\"]], scan_annotations):\n",
    "                negative_candidates.append([cand[\"coordX\"], cand[\"coordY\"], cand[\"coordZ\"]])\n",
    "\n",
    "        # Limit to a few negatives per scan\n",
    "        sampled_candidates = random.sample(negative_candidates, min(len(negative_candidates), max_negatives_per_scan))\n",
    "\n",
    "        for idx, world_coord in enumerate(sampled_candidates):\n",
    "            voxel_coord = world_to_voxel(world_coord, origin, spacing)\n",
    "            patch = extract_patch(volume, voxel_coord, patch_size)\n",
    "\n",
    "            # Skip mostly empty patches\n",
    "            if patch.mean() < intensity_threshold:\n",
    "                continue\n",
    "\n",
    "            # Save\n",
    "            filename = f\"{seriesuid}_neg_{idx}.npy\"\n",
    "            np.save(os.path.join(output_folder, filename), patch)\n",
    "\n",
    "def extract_patches_from_annotations(\n",
    "    annotation_csv, \n",
    "    metadata_csv, \n",
    "    output_folder, \n",
    "    patch_size=32\n",
    "):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    annotations = pd.read_csv(annotation_csv)\n",
    "    metadata = pd.read_csv(metadata_csv)\n",
    "\n",
    "    for _, row in annotations.iterrows():\n",
    "        case_id = row['seriesuid']\n",
    "        meta = metadata[metadata[\"case_id\"] == case_id]\n",
    "\n",
    "        if meta.empty:\n",
    "            continue\n",
    "\n",
    "        meta = meta.iloc[0]\n",
    "        origin = np.array([meta[\"origin_z\"], meta[\"origin_y\"], meta[\"origin_x\"]])\n",
    "        spacing = np.array([meta[\"spacing_z\"], meta[\"spacing_y\"], meta[\"spacing_x\"]])\n",
    "\n",
    "        raw_path = meta[\"path\"]\n",
    "        normalized_path = normalize_path(raw_path)\n",
    "        image = np.load(normalized_path)  # shape: [Z, Y, X]\n",
    "\n",
    "        world_coord = np.array([row['coordZ'], row['coordY'], row['coordX']])\n",
    "        voxel_coord = world_to_voxel(world_coord, origin, spacing)\n",
    "        z, y, x = voxel_coord\n",
    "        half = patch_size // 2\n",
    "\n",
    "        # Compute slice bounds, clipped to image\n",
    "        z_min = max(z - half, 0)\n",
    "        z_max = min(z + half, image.shape[0])\n",
    "        y_min = max(y - half, 0)\n",
    "        y_max = min(y + half, image.shape[1])\n",
    "        x_min = max(x - half, 0)\n",
    "        x_max = min(x + half, image.shape[2])\n",
    "\n",
    "        patch = image[z_min:z_max, y_min:y_max, x_min:x_max]\n",
    "\n",
    "        # Compute padding sizes if patch is smaller than desired\n",
    "        pad_z = (patch_size - patch.shape[0])\n",
    "        pad_y = (patch_size - patch.shape[1])\n",
    "        pad_x = (patch_size - patch.shape[2])\n",
    "\n",
    "        pad_z = (0, pad_z) if pad_z > 0 else (0, 0)\n",
    "        pad_y = (0, pad_y) if pad_y > 0 else (0, 0)\n",
    "        pad_x = (0, pad_x) if pad_x > 0 else (0, 0)\n",
    "\n",
    "        patch = np.pad(patch, [pad_z, pad_y, pad_x], mode='constant', constant_values=0)\n",
    "\n",
    "        save_path = os.path.join(output_folder, f\"{case_id}_{z}_{y}_{x}_pos.npy\")\n",
    "        np.save(save_path, patch)\n",
    "        print(f\"Saved patch: {save_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cuda)",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
